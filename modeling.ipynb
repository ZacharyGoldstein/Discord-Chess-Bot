{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import *\n",
    "from plotnine import *\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import requests\n",
    "from sklearn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_csv(\"data/lichess_swiss_rating_histories_1.csv\",parse_dates=['date']),\n",
    "                pd.read_csv(\"data/lichess_swiss_rating_histories_2.csv\",parse_dates=['date'])])\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The latest date we have data on\n",
    "max_outcome_date = df['date'].max()\n",
    "# The latest date that can be used for training to ensure we'll always have 2 years in advance of outcomes data\n",
    "max_training_date = max_outcome_date - timedelta(days=365*2)\n",
    "max_outcome_date,max_training_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The earliest date we have data on\n",
    "minn_training_date = df['date'].min()\n",
    "minn_training_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The latest ratings that can be used for training\n",
    "df_training = df.query('date<=@max_training_date')\n",
    "df_outcomes = df.query('date>@max_training_date')\n",
    "latest_training_ratings = df_training.sort_values(\"date\",ascending=False).drop_duplicates(['user_id','time_control'])\n",
    "latest_training_ratings.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_training_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_training_ratings['rating'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "- Target time control (likely interacted with various other features)\n",
    "- Target rating gain\n",
    "- Current rating (likely nonlinear relationship)\n",
    "- Rating growth in last 30 days / 90 days / 180 days\n",
    "- Rating volatility measures\n",
    "- Peak historical rating relative to current rating\n",
    "- Rating in other time controls + puzzles\n",
    "- Rating growth in other time controls + puzzles\n",
    "- Difference between other time control ratings + target time control rating\n",
    "- How long you've been on lichess\n",
    "- How many games you've played (ever, and within last 30 days, and within the target time control - if you haven't played many it could mean more uncertainty). Consider that most discord bot users will have played more recent rated games in the target time control than the typical user in the training data. \n",
    "- Last time you played a rated game in the target time control (if it's a long time ago, it could mean more uncertainty)\n",
    "- Have you recently been playing puzzles? What about slow games? That could indicate seriousness about improvement\n",
    "\n",
    "## Outcomes\n",
    "- Will you ever achieve a rating that's X rating points higher than your current rating in the next Y months (X is calculated from target rating submitted by user, Y = 24?)\n",
    "- If so, when will you first reach the target rating? (point estimate + prediction interval of dates) - use number of days as outcome, then transform to date for the bot message\n",
    "- Try to tweak model to avoid negative predictions, and manually override when needed. Same with predictions greater than 2 years out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratings from X days before the max training date\n",
    "max_training_date_minus_30 = max_training_date-timedelta(days=30)\n",
    "max_training_date_minus_90 = max_training_date-timedelta(days=90)\n",
    "max_training_date_minus_180 = max_training_date-timedelta(days=180)\n",
    "hist_ratings_30 = df_training.query('date<=@max_training_date_minus_30').sort_values(\"date\",ascending=False).drop_duplicates(['user_id','time_control'])\n",
    "hist_ratings_90 = df_training.query('date<=@max_training_date_minus_90').sort_values(\"date\",ascending=False).drop_duplicates(['user_id','time_control'])\n",
    "hist_ratings_180 = df_training.query('date<=@max_training_date_minus_180').sort_values(\"date\",ascending=False).drop_duplicates(['user_id','time_control'])\n",
    "hist_ratings_180.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Peak ratings\n",
    "hist_ratings_peak = df_training.sort_values(\"rating\",ascending=False).drop_duplicates(['user_id','time_control'])\n",
    "outcome_ratings_peak = df_outcomes.sort_values(\"rating\",ascending=False).drop_duplicates(['user_id','time_control'])\n",
    "hist_ratings_peak.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating volatility\n",
    "rating_stdev_30 = df_training.query('date>=@max_training_date_minus_30').groupby(['user_id','time_control'])['rating'].std().fillna(0).reset_index().rename(columns={\"rating\":\"rating_stdev_30\"})\n",
    "rating_stdev_90 = df_training.query('date>=@max_training_date_minus_90').groupby(['user_id','time_control'])['rating'].std().fillna(0).reset_index().rename(columns={\"rating\":\"rating_stdev_90\"})\n",
    "rating_stdev_180 = df_training.query('date>=@max_training_date_minus_180').groupby(['user_id','time_control'])['rating'].std().fillna(0).reset_index().rename(columns={\"rating\":\"rating_stdev_180\"})\n",
    "rating_stdev_30.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency of rating updates\n",
    "rating_updates_30 = df_training.query('date>=@max_training_date_minus_30').groupby(['user_id','time_control']).size().reset_index().rename(columns={0:\"rating_updates_30\"})\n",
    "rating_updates_90 = df_training.query('date>=@max_training_date_minus_90').groupby(['user_id','time_control']).size().reset_index().rename(columns={0:\"rating_updates_90\"})\n",
    "rating_updates_90.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-target time control ratings\n",
    "non_target_rating_updates_30 = rating_updates_30.pivot(index='user_id',columns='time_control',values='rating_updates_30').fillna(0)\n",
    "non_target_rating_updates_30.columns = ['blitz_updates_30','bullet_updates_30','classical_updates_30','rapid_updates_30']\n",
    "non_target_rating_updates_30.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add features to base table\n",
    "df_base = latest_training_ratings.merge(hist_ratings_30[['user_id','time_control','rating']],\n",
    "                how='left',on=['user_id','time_control'],suffixes=['_latest','_30']).merge(\n",
    "            hist_ratings_90[['user_id','time_control','rating']],\n",
    "                how='left',on=['user_id','time_control']).merge(\n",
    "            hist_ratings_180[['user_id','time_control','rating']],\n",
    "                how='left',on=['user_id','time_control'],suffixes=['_90','_180']).merge(\n",
    "            hist_ratings_peak[['user_id','time_control','rating']].rename(columns={'rating':'rating_peak'}),\n",
    "                how='left',on=['user_id','time_control']).merge(\n",
    "            rating_updates_30,how='left',on=['user_id','time_control']).merge(\n",
    "            rating_updates_90,how='left',on=['user_id','time_control']).merge(\n",
    "            rating_stdev_30,how='left',on=['user_id','time_control']).merge(\n",
    "            rating_stdev_90,how='left',on=['user_id','time_control']).merge(\n",
    "            rating_stdev_180,how='left',on=['user_id','time_control']).merge(\n",
    "            non_target_rating_updates_30,how='left',on='user_id'\n",
    ")\n",
    "df_base['rating_30_diff'] = df_base['rating_latest']-df_base['rating_30']\n",
    "df_base['rating_90_diff'] = (df_base['rating_latest']-df_base['rating_90']).combine_first(df_base['rating_30_diff'])\n",
    "df_base['rating_180_diff'] = (df_base['rating_latest']-df_base['rating_180']).combine_first(df_base['rating_90_diff'])\n",
    "df_base['rating_peak_diff'] = df_base['rating_latest']-df_base['rating_peak']\n",
    "df_base['time_control_copy'] = df_base['time_control']\n",
    "df_base['rating_latest_rounded'] = df_base['rating_latest'].round(-2)\n",
    "df_base['rating_latest_squared'] = df_base['rating_latest']**2\n",
    "df_base['rating_latest_rounded_200'] = 200*np.ceil(df_base['rating_latest_rounded']/200).astype(int)\n",
    "df_base['rating_latest_rounded_300'] = 300*np.ceil(df_base['rating_latest_rounded']/300).astype(int)\n",
    "df_base = pd.get_dummies(df_base,columns=['time_control_copy'],prefix_sep=\"\")\n",
    "df_base.columns = [x.replace(\"time_control_copy\",\"\").lower() for x in df_base.columns]\n",
    "print(df_base.shape)\n",
    "df_base.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to people who have played rated games in the time control before 30 days ago...\n",
    "# ... and have played at least one rated game in the time control within the last 30 days\n",
    "df_base = df_base[(df_base['rating_30'].notna())&(df_base['date']>=max_training_date_minus_30)]\n",
    "print(df_base.shape)\n",
    "print(df_base['user_id'].nunique())\n",
    "df_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the distribution of rating gains over the two year period?\n",
    "## Use this to come up with reasonable target rating ranges where I'll have a decent sample size to work with when estimating how long it'll take\n",
    "df_max_rating_gains = df_base.merge(outcome_ratings_peak,on=['user_id','time_control'],how='inner')\n",
    "df_max_rating_gains['max_gain'] = df_max_rating_gains['rating']-df_max_rating_gains['rating_latest']\n",
    "df_max_rating_gains['rating_bucket'] = df_max_rating_gains['rating_latest'].apply(lambda x: 1 if x < 1550 else (2 if x < 1900 else 3))\n",
    "df_max_rating_gains.groupby(\"rating_bucket\")['max_gain'].describe(percentiles=[.25,.5,.75,.9,.95,.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate target ratings\n",
    "df_targets = pd.concat([df_base for x in range(5)])\n",
    "np.random.seed(1)\n",
    "def get_target_rating_gain(x):\n",
    "    # Right side of interval is exclusive, so this goes from 1-3\n",
    "    die = np.random.randint(1,4)\n",
    "    if die == 1:\n",
    "        return np.random.randint(1,100)\n",
    "    elif die == 2:\n",
    "        return np.random.randint(1,300)\n",
    "    elif die == 3:\n",
    "        if x < 1550:\n",
    "            return np.random.randint(100,700)\n",
    "        elif x < 1900:\n",
    "            return np.random.randint(100,500)\n",
    "        else:\n",
    "            return np.random.randint(100,400)\n",
    "    else:\n",
    "        print(1/0)\n",
    "\n",
    "df_targets['target_rating_gain'] = df_targets['rating_latest'].apply(get_target_rating_gain)\n",
    "df_targets.drop_duplicates(subset=['user_id','time_control','target_rating_gain'],inplace=True)\n",
    "df_targets['target_rating'] = df_targets['rating_latest'] + df_targets['target_rating_gain']\n",
    "df_targets['target_rating_gain_rounded'] = df_targets['target_rating_gain'].round(-2)\n",
    "df_targets['target_rating_gain_squared'] = df_targets['target_rating_gain']**2\n",
    "print(df_targets.shape)\n",
    "df_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets.groupby(\"rating_latest_rounded\")['target_rating_gain'].describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(df_targets.sample(2000),aes(x='rating_latest',y='target_rating')) +\n",
    " geom_point(size=.1) +\n",
    " scale_x_continuous(breaks=list(range(800,2500,200))) +\n",
    "  scale_y_continuous(breaks=list(range(800,2500,200)))\n",
    "\n",
    "        \n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_targets[['user_id','time_control','target_rating','date']].copy()\n",
    "df_temp = df_temp.merge(df_outcomes,on=['user_id','time_control'],how='outer',suffixes=['_latest','_future'])\n",
    "print(df_temp.shape)\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Successes - filter to where future rating >= target rating, then take earliest date for each user/time control\n",
    "df_successes = df_temp.query('rating>=target_rating').sort_values(\"date_future\").drop_duplicates(['user_id','time_control','target_rating'])\n",
    "print(df_successes.shape)\n",
    "df_successes.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Successes and failures \n",
    "df_bin = df_targets.merge(df_successes[['user_id','time_control','target_rating','date_future']],on=['user_id','time_control','target_rating'],how='left')\n",
    "# Was the target rating achieved?\n",
    "df_bin['y_bin'] = df_bin['date_future'].notna().astype(int)\n",
    "# If so, when?\n",
    "df_bin['y_cont'] = (df_bin['date_future']-max_training_date).dt.days\n",
    "print(df_bin.shape)\n",
    "df_bin.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont = df_bin[df_bin['y_bin']==1].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bin_by_rating = df_bin.groupby([\"rating_latest_rounded\",\"time_control\"])['y_bin'].agg([np.mean,len])\n",
    "(ggplot(y_bin_by_rating[y_bin_by_rating['len']>=25].reset_index(),\n",
    "        aes(x='rating_latest_rounded',y='mean',color='time_control')) +\n",
    " geom_point() +\n",
    "      scale_x_continuous(breaks=list(range(600,2600,200))) +\n",
    "         ylim([0,1])\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bin_by_gain = df_bin.groupby([\"target_rating_gain_rounded\",\"time_control\"])['y_bin'].agg([np.mean,len])\n",
    "(ggplot(y_bin_by_gain[y_bin_by_gain['len']>=25].reset_index(),\n",
    "        aes(x='target_rating_gain_rounded',y='mean',color='time_control')) +\n",
    " geom_point() +\n",
    "         ylim([0,1])\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_by_quant_vars = df_bin.groupby(['target_rating_gain_rounded','rating_latest_rounded'])['y_bin'].mean().reset_index().round(2)\n",
    "bin_by_quant_vars.pivot(index='target_rating_gain_rounded',columns='rating_latest_rounded',values='y_bin').iloc[:-2,6:-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(bin_by_quant_vars.query(\"rating_latest_rounded>=1200\"),aes(x='target_rating_gain_rounded',y='y_bin',group='rating_latest_rounded',\n",
    "       color='rating_latest_rounded')) +\n",
    "geom_line())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As target rating gain increases, the effect of latest rating should go from zero to more negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_days_by_quant_vars = df_cont.groupby(['target_rating_gain_rounded','rating_latest_rounded'])['y_cont'].mean().reset_index().round()\n",
    "mean_days_by_quant_vars.pivot(index='target_rating_gain_rounded',columns='rating_latest_rounded',values='y_cont').iloc[:-1,6:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_days_by_quant_vars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cont_by_rating = df_cont.groupby([\"rating_latest_rounded\",'time_control'])['y_cont'].agg([np.mean,len]).reset_index()\n",
    "y_cont_by_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(y_cont_by_rating.query('len>=25'),aes(x='rating_latest_rounded',y='mean',color='time_control')) +\n",
    "        geom_point() +\n",
    "    ylim(0,500) +\n",
    "     scale_x_continuous(breaks=list(range(600,2600,200)))\n",
    "        \n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_outcome_by_group = df_cont.groupby(['target_rating_gain_rounded','time_control','rating_latest_rounded'])['y_cont'].agg([np.mean,len]).reset_index()\n",
    "(ggplot(mean_outcome_by_group.query('len>=30'),aes(x='target_rating_gain_rounded',y='mean')) +\n",
    "      geom_point())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier checks\n",
    "## High gains\n",
    "df_cont['target_rating_gain'].describe(percentiles=[x/10 for x in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Quick gains\n",
    "df_cont[df_cont['target_rating_gain']>100]['y_cont'].describe(percentiles=[x/10 for x in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Fast-improvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont['fast_improver'] = (df_cont['y_cont']<34).astype(int)\n",
    "df_cont.groupby(\"fast_improver\")['rating_30_diff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont.groupby([\"fast_improver\",\"time_control\"])['rating_updates_30'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-target ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont[['y_cont','rating_updates_30','blitz_updates_30','bullet_updates_30','rapid_updates_30','classical_updates_30']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin_train = df_bin.sample(frac=.8,random_state=1)\n",
    "df_bin_test = df_bin.loc[~df_bin.index.isin(df_bin_train.index)].copy()\n",
    "df_cont_train = df_cont.sample(frac=.8,random_state=1)\n",
    "df_cont_test = df_cont.iloc[~df_cont.index.isin(df_cont_train.index)].copy()\n",
    "len(df_bin_train),len(df_bin_test),len(df_cont_train),len(df_cont_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For refrence, a simple logit based only on target rating gain and latest rating\n",
    "logit_simple = smf.logit(formula=\"y_bin~target_rating_gain+rating_latest\",data=df_bin_train).fit()\n",
    "logit_simple.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_rating_gain_squared*rating_latest\n",
    "logit = smf.logit(formula=\"\"\"\n",
    "y_bin~target_rating_gain*rating_latest*bullet+target_rating_gain*rating_latest*blitz+\n",
    "target_rating_gain*rating_latest*classical+\n",
    "\n",
    "target_rating_gain_squared*rating_latest+\n",
    "\n",
    "rating_peak_diff*target_rating_gain+rating_180_diff*bullet+rating_180_diff*blitz+\n",
    "\n",
    "rating_updates_30+\n",
    "\n",
    "rating_updates_90*bullet+rating_updates_90*blitz+\n",
    "\n",
    "rating_stdev_90\n",
    "\"\"\",data=df_bin_train).fit()\n",
    "logit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "ols = smf.ols(formula=\"\"\"\n",
    "y_cont~\n",
    "target_rating_gain*rating_latest*bullet+target_rating_gain*rating_latest*blitz+target_rating_gain*rating_latest*classical+\n",
    "target_rating_gain_squared*bullet+target_rating_gain_squared*blitz+\n",
    "rating_latest_squared+\n",
    "\n",
    "rating_peak_diff*bullet+rating_peak_diff*blitz+\n",
    "rating_peak_diff*target_rating_gain+\n",
    "\n",
    "rating_180_diff*bullet+rating_180_diff*blitz+\n",
    "\n",
    "rating_90_diff+\n",
    "\n",
    "rating_30_diff*bullet+rating_30_diff*classical+\n",
    "\n",
    "rating_updates_30+rating_updates_90*blitz+rating_updates_90*classical+\n",
    "\n",
    "rating_stdev_30\n",
    "\n",
    "\"\"\",data=df_cont_train).fit()\n",
    "ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intervals\n",
    "ols.get_prediction(df_cont_train).summary_frame().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin_test['prob'] = logit.predict(df_bin_test)\n",
    "df_bin_test['prob_simple'] = logit_simple.predict(df_bin_test)\n",
    "df_bin_test['prob'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(df_bin_test['prob'].mean(),3))\n",
    "print(round(df_bin_test['y_bin'].mean(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "## Baseline\n",
    "print(round(((np.ones(len(df_bin_test))-df_bin_test['y_bin'])**2).mean(),3))\n",
    "## Logit model\n",
    "print(round(((df_bin_test['prob']-df_bin_test['y_bin'])**2).mean(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in df_bin_test['time_control'].unique():\n",
    "    data = df_bin_test.query(\"time_control==@x\")\n",
    "    print(x)\n",
    "    print(round(((data['prob']-data['y_bin'])**2).mean(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin_test['decile'] = pd.qcut(df_bin_test['prob'],q=10)\n",
    "deciles = df_bin_test.groupby('decile')[['prob','y_bin']].mean().reset_index()\n",
    "deciles['index'] = np.arange(len(deciles))\n",
    "decile_probs = deciles[['prob','index']].rename(columns={\"prob\":\"value\"})\n",
    "decile_probs['variable'] = 'Mean Probability'\n",
    "decile_actuals = deciles[['y_bin','index']].rename(columns={\"y_bin\":\"value\"})\n",
    "decile_actuals['variable'] = 'Actual Proportion'\n",
    "deciles = pd.concat([decile_probs,decile_actuals],axis=0)\n",
    "decile_plot = (ggplot(deciles,aes(x='index',y='value',fill='variable')) +\n",
    " geom_bar(stat='identity',position='dodge') +\n",
    "               scale_x_continuous(breaks=list(range(0,10)),\n",
    "                                 labels=list(range(1,11))) +\n",
    "               labs(x = \"Decile\",y = \"Value\",\n",
    "                   fill = \"Variable\", title = \"Logit Test Set Deciles\")\n",
    ")\n",
    "ggsave(decile_plot,\"plots/test_decile_plot.png\",verbose=False)\n",
    "decile_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(df_bin_test.query('y_bin==0'),aes(x='prob')) +\n",
    "geom_histogram(bins=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the ones with high-prob that are zeros (where we're overpredicting)\n",
    "df_bin_test.query(\"prob>=.75&y_bin==0\").groupby([\"time_control\",\"rating_latest_rounded_300\",\"target_rating_gain_rounded\"]).size().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(df_bin_test.query('y_bin==1'),aes(x='prob')) +\n",
    "geom_histogram(bins=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(df_bin_test,aes(x='prob')) +\n",
    "geom_histogram(bins=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtabs_bin = df_bin_test.groupby(['time_control','target_rating_gain_rounded','rating_latest_rounded_300'])[['y_bin','prob']].agg([np.mean,len]).iloc[:,:-1].round(2)\n",
    "xtabs_bin.columns = ['prop_actual','n','mean_prob']\n",
    "xtabs_bin.reset_index(inplace=True)\n",
    "xtabs_bin['diff'] = xtabs_bin['mean_prob'] - xtabs_bin['prop_actual']\n",
    "xtabs_bin['abs_diff'] = xtabs_bin['diff'].abs()\n",
    "xtabs_bin.query(\"n>=50\").sort_values(\"abs_diff\",ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin_test.groupby(['rating_latest_rounded_200'])[['y_bin','prob']].agg([np.mean,len]).iloc[:,:-1].round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin_test.groupby(['target_rating_gain_rounded'])[['y_bin','prob']].agg([np.mean,len]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtabs_bin.query(\"time_control=='Classical'\").pivot(index='target_rating_gain_rounded',columns='rating_latest_rounded_300',values='prop_actual').iloc[:,1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtabs_bin.query(\"time_control=='Classical'\").pivot(index='target_rating_gain_rounded',columns='rating_latest_rounded_300',values='mean_prob').iloc[:,1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtabs_bin.query(\"time_control=='Classical'\").pivot(index='target_rating_gain_rounded',columns='rating_latest_rounded_300',values='diff').iloc[:,1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtabs_bin.query(\"time_control=='Classical'\").pivot(index='target_rating_gain_rounded',columns='rating_latest_rounded_300',values='n').iloc[:,1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.roc_auc_score(y_true=df_bin_test['y_bin'],y_score=df_bin_test['prob_simple']).round(3))\n",
    "print(metrics.roc_auc_score(y_true=df_bin_test['y_bin'],y_score=df_bin_test['prob']).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.roc_auc_score(y_true=df_bin_test.query(\"time_control=='Bullet'\")['y_bin'],y_score=df_bin_test.query(\"time_control=='Bullet'\")['prob']).round(2))\n",
    "print(metrics.roc_auc_score(y_true=df_bin_test.query(\"time_control=='Blitz'\")['y_bin'],y_score=df_bin_test.query(\"time_control=='Blitz'\")['prob']).round(2))\n",
    "print(metrics.roc_auc_score(y_true=df_bin_test.query(\"time_control=='Rapid'\")['y_bin'],y_score=df_bin_test.query(\"time_control=='Rapid'\")['prob']).round(2))\n",
    "print(metrics.roc_auc_score(y_true=df_bin_test.query(\"time_control=='Classical'\")['y_bin'],y_score=df_bin_test.query(\"time_control=='Classical'\")['prob']).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about for rating gains that are harder to predict?\n",
    "df_bin_high_gains = df_bin_test.query(\"target_rating_gain>=50&target_rating_gain<200\")\n",
    "print(metrics.roc_auc_score(y_true=df_bin_high_gains['y_bin'],y_score=df_bin_high_gains['prob_simple']).round(2))\n",
    "print(metrics.roc_auc_score(y_true=df_bin_high_gains['y_bin'],y_score=df_bin_high_gains['prob']).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont_test['y_cont'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont_test['pred'] = ols.predict(df_cont_test)\n",
    "# Set negative predictions to zero and > 2 year predictions to 2 years\n",
    "df_cont_test.loc[df_cont_test['pred']<0,'pred'] = 0\n",
    "df_cont_test.loc[df_cont_test['pred']>365*2,'pred'] = 365*2\n",
    "df_cont_test['pred'].describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont_test['error'] = df_cont_test['pred']-df_cont_test['y_cont']\n",
    "df_cont_test['abs_error'] = df_cont_test['error'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont_test['error'].describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont_test['abs_error'].describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont_test.groupby(\"time_control\")['abs_error'].describe().round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_summary = df_cont_test.groupby(['target_rating_gain_rounded','rating_latest_rounded','time_control'])[['pred','y_cont','abs_error','error']].agg([np.mean]).round().astype(int)\n",
    "sizes = df_cont_test.groupby(['target_rating_gain_rounded','rating_latest_rounded','time_control']).size().reset_index()\n",
    "sizes.rename(columns={0:\"n\"},inplace=True)\n",
    "error_summary.columns = ['mean_pred','mean_actual','mean_abs_error','mean_error']\n",
    "error_summary = error_summary.reset_index().merge(sizes,on=['target_rating_gain_rounded','rating_latest_rounded','time_control'])\n",
    "error_summary = error_summary.query('n>30')\n",
    "error_summary.sort_values(\"mean_error\",ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_summary.query(\"time_control=='Rapid'\").pivot(index='target_rating_gain_rounded',columns='rating_latest_rounded',values='mean_actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_summary.query(\"time_control=='Rapid'\").pivot(index='target_rating_gain_rounded',columns='rating_latest_rounded',values='mean_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_summary.query(\"time_control=='Rapid'\").pivot(index='target_rating_gain_rounded',columns='rating_latest_rounded',values='mean_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_summary.query(\"time_control=='Classical'\").pivot(index='target_rating_gain_rounded',columns='rating_latest_rounded',values='n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(error_summary.query(\"time_control=='Blitz'&target_rating_gain_rounded<=300\")) +\n",
    "geom_point(aes(x='rating_latest_rounded',y='mean_pred'),color='red')+\n",
    " geom_point(aes(x='rating_latest_rounded',y='mean_actual'),color='blue')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval for core use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most users in discord will be rated between 1200-2200...\n",
    "#... trying to improve between 0-200 rating points...\n",
    "# in blitz or rapid\n",
    "# How does the model do with them?\n",
    "df_cont_core = df_cont_test.query(\"target_rating_gain<=200&rating_latest>=1200&rating_latest<=2200\")\n",
    "df_cont_core.groupby(\"time_control\")['abs_error'].describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont_small = df_cont_test.query(\"target_rating_gain<=75&rating_latest>=1200&rating_latest<=2200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont_small.groupby(\"time_control\")['abs_error'].describe().round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval for the worst misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont_test.sort_values(\"error\",ascending=False).head(15).drop(['y_bin','fast_improver','target_rating_gain_rounded','target_rating_gain_squared','bullet','classical','rapid','blitz','rating_latest_squared','date','rating_latest_rounded','rating_latest_rounded_200','rating_latest_rounded_300','rating_90_diff','rating_peak_diff','rating_180_diff','classical_updates_30','rapid_updates_30','blitz_updates_30','bullet_updates_30','rating_180','rating_stdev_180'],axis=1).round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to log model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dates = df_training.drop_duplicates(subset=['user_id','time_control'],keep='first').rename(columns={\"date\":\"start_date\"})\n",
    "df_training_merged = df_training.merge(start_dates.drop(\"rating\",axis=1),on=['user_id','time_control'])\n",
    "df_training_merged['days_since_start'] = (df_training_merged['date']-df_training_merged['start_date'])/timedelta(days=1)\n",
    "df_training_merged['exp_rating'] = 3**(df_training_merged['rating']/300)\n",
    "df_training_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_coefs = df_training_merged.groupby(['user_id','time_control','start_date']).apply(lambda x:\n",
    "    np.polyfit(x['days_since_start'],x['exp_rating'],1) if len(x)>25 else None).reset_index().dropna()\n",
    "log_coefs.rename(columns={0:\"coefs\"},inplace=True)\n",
    "log_coefs['intercept'] = log_coefs['coefs'].apply(lambda x: x[0])\n",
    "log_coefs['slope'] = log_coefs['coefs'].apply(lambda x: x[1])\n",
    "log_coefs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont_log_preds = df_cont_test[['user_id','time_control','target_rating','target_rating_gain',\n",
    "    'y_cont','pred','error','abs_error']].rename(columns={\"error\":\"ols_error\",\"abs_error\":\"ols_abs_error\"}).merge(\n",
    "    log_coefs.drop(\"coefs\",axis=1),on=['user_id','time_control'],how='inner')\n",
    "df_cont_log_preds['log_model_days_since_start'] = df_cont_log_preds.apply(lambda x: ((3 ** (x['target_rating']/300)) - x['slope'])/x['intercept'],axis=1)\n",
    "df_cont_log_preds['max_training_date'] = max_training_date\n",
    "df_cont_log_preds['days_since_start'] = (df_cont_log_preds['max_training_date'] - df_cont_log_preds['start_date'])/timedelta(days=1)\n",
    "df_cont_log_preds['log_model_days_pred'] = df_cont_log_preds['log_model_days_since_start']-df_cont_log_preds['days_since_start']\n",
    "df_cont_log_preds.loc[df_cont_log_preds['log_model_days_pred']<0,\"log_model_days_pred\"] = 0\n",
    "df_cont_log_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont_log_preds['log_error'] = df_cont_log_preds['log_model_days_pred']-df_cont_log_preds['y_cont']\n",
    "df_cont_log_preds['log_abs_error'] = df_cont_log_preds['log_error'].abs()\n",
    "df_cont_log_preds[['ols_error','ols_abs_error','log_error','log_abs_error']].describe().round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cont_log_preds.shape) # fewer predictions because of >25 days requirement\n",
    "print(df_cont_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont_log_preds.groupby(\"time_control\")[['ols_abs_error','log_abs_error']].agg([np.mean,np.median]).round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible objection is that by definition the answer must be < 2 years, so OLS has unfair advantage\n",
    "# To address, filter to where log model predictions are < 1 year\n",
    "under_year_log_preds = df_cont_log_preds.query(\"log_model_days_pred<=365\")\n",
    "under_year_log_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_year_log_preds[['ols_error','ols_abs_error','log_error','log_abs_error']].describe().round().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit.params.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols.params.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params=pd.concat([logit.params,ols.params],axis=1).reset_index()\n",
    "model_params.columns = ['var_name','logit','ols']\n",
    "#model_params.to_csv(\"data/model_params_20210825.csv\",index=False)\n",
    "model_params.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = pd.read_csv(\"data/model_params_20210825.csv\")\n",
    "model_params.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert rating history info from JSON to Dataframe\n",
    "def process_rating_history(response_json):\n",
    "    rating_history = dict()\n",
    "    for x in response_json:\n",
    "        if x['name'] in ['Bullet','Blitz','Rapid','Classical']:\n",
    "            tbl = pd.DataFrame(x['points'])\n",
    "            if len(tbl) == 0: continue\n",
    "            tbl.columns = ['year','month','day','rating']\n",
    "            tbl['month'] = tbl['month']+1\n",
    "            tbl['date'] = pd.to_datetime(tbl.year*10000+tbl.month*100+tbl.day,format='%Y%m%d')\n",
    "            rating_history[x['name']] = tbl\n",
    "    return(rating_history)\n",
    "\n",
    "# Get the values that are inputs to the models\n",
    "def get_predictor_values(rating_history,target_rating,target_time_control):\n",
    "    target_rating_history = rating_history[target_time_control]\n",
    "    t_minus_30 = datetime.today()-timedelta(days=30)\n",
    "    t_minus_90 = datetime.today()-timedelta(days=90)\n",
    "    t_minus_180 = datetime.today()-timedelta(days=180)\n",
    "    target_rating_history_30 = target_rating_history.query('date>=@t_minus_30')\n",
    "    target_rating_history_90 = target_rating_history.query('date>=@t_minus_90')\n",
    "    target_rating_history_180 = target_rating_history.query('date>=@t_minus_180')    \n",
    "    rating_latest = target_rating_history['rating'].values[-1]\n",
    "    target_rating_gain = target_rating-rating_latest\n",
    "    predictor_values = dict(Intercept=1,target_rating_gain=target_rating_gain,\n",
    "        target_rating_gain_squared=target_rating_gain**2,\n",
    "        rating_latest=rating_latest,\n",
    "        rating_latest_squared = rating_latest**2,\n",
    "        bullet = int(target_time_control == 'Bullet'), blitz = int(target_time_control == 'Blitz'),\n",
    "        rapid = int(target_time_control == 'Rapid'), classical = int(target_time_control == 'Classical'),\n",
    "        rating_peak_diff = rating_latest-target_rating_history['rating'].max(),\n",
    "        rating_30_diff = rating_latest-target_rating_history_30['rating'].values[0],\n",
    "        rating_90_diff = rating_latest-target_rating_history_90['rating'].values[0],\n",
    "        rating_180_diff = rating_latest-target_rating_history_180['rating'].values[0],\n",
    "        rating_updates_30 = len(target_rating_history_30['rating']),\n",
    "        rating_updates_90 = len(target_rating_history_90['rating']),\n",
    "        rating_stdev_30 = target_rating_history_30['rating'].std() if len(target_rating_history_30) > 1 else 0,\n",
    "        rating_stdev_90 = target_rating_history_90['rating'].std() if len(target_rating_history_90) > 1 else 0\n",
    "                                   )\n",
    "    return(predictor_values)\n",
    "\n",
    "# Calculate the probability of success given a set of predictor values and a classification model\n",
    "def get_prob_success(predictor_values,model_params):\n",
    "    logit_params = model_params[['var_name','logit']].dropna()\n",
    "    linear_combo = 0\n",
    "    for i in range(len(logit_params)):\n",
    "        var_name = logit_params['var_name'].values[i]\n",
    "        coef = logit_params['logit'].values[i]\n",
    "        if ':' in var_name:\n",
    "            var_names = var_name.split(\":\")\n",
    "            value = 1\n",
    "            for j in var_names:\n",
    "                value *= predictor_values[j]\n",
    "        else:\n",
    "            value = predictor_values[var_name]\n",
    "        linear_combo += coef*value\n",
    "    return str(round(100*1/(1+np.exp(-1*(linear_combo)))))+\"%\"\n",
    "\n",
    "# Calculate the predicted days until target rating given a set of predictor values and a regression model\n",
    "def get_predicted_date(predictor_values,model_params):\n",
    "    ols_params = model_params[['var_name','ols']].dropna()\n",
    "    predicted_days = 0\n",
    "    for i in range(len(ols_params)):\n",
    "        var_name = ols_params['var_name'].values[i]\n",
    "        coef = ols_params['ols'].values[i]\n",
    "        if ':' in var_name:\n",
    "            var_names = var_name.split(\":\")\n",
    "            value = 1\n",
    "            for j in var_names:\n",
    "                value *= predictor_values[j]\n",
    "        else:\n",
    "            value = predictor_values[var_name]\n",
    "        predicted_days += coef*value\n",
    "    predicted_date = (datetime.today()+timedelta(days=predicted_days)).strftime(format=\"%B %d, %Y\")\n",
    "    return(predicted_date)\n",
    "\n",
    "# Return the predictions based on discord inputs\n",
    "def score(username,target_rating,target_time_control,model_params):\n",
    "    url = f'https://lichess.org/api/user/{username}/rating-history'\n",
    "    response = requests.get(url)\n",
    "    response_json = response.json()\n",
    "    if response.status_code != 200:\n",
    "        return(f\"API ERROR: {response.status_code}\")\n",
    "    else:\n",
    "        rating_history = process_rating_history(response_json)\n",
    "        predictor_values = get_predictor_values(rating_history,target_rating,target_time_control)\n",
    "        #print(predictor_values)\n",
    "        prob_success = get_prob_success(predictor_values,model_params)\n",
    "        predicted_date = get_predicted_date(predictor_values,model_params)\n",
    "        return(prob_success,predicted_date)\n",
    "score(username = \"\",target_rating = 2000,\n",
    "      target_time_control = \"Rapid\",model_params = model_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

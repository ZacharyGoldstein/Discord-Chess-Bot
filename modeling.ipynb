{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import *\n",
    "from plotnine import *\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_csv(\"data/lichess_swiss_rating_histories_1.csv\",parse_dates=['date']),\n",
    "                pd.read_csv(\"data/lichess_swiss_rating_histories_2.csv\",parse_dates=['date'])])\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The latest date we have data on\n",
    "max_outcome_date = df['date'].max()\n",
    "# The latest date that can be used for training to ensure we'll always have 2 years in advance of outcomes data\n",
    "max_training_date = max_outcome_date - timedelta(days=365*2)\n",
    "max_outcome_date,max_training_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The earliest date we have data on\n",
    "minn_training_date = df['date'].min()\n",
    "minn_training_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The latest ratings that can be used for training\n",
    "df_training = df.query('date<=@max_training_date')\n",
    "df_outcomes = df.query('date>@max_training_date')\n",
    "latest_training_ratings = df_training.sort_values(\"date\",ascending=False).drop_duplicates(['user_id','time_control'])\n",
    "latest_training_ratings.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratings from X days before the max training date\n",
    "max_training_date_minus_30 = max_training_date-timedelta(days=30)\n",
    "max_training_date_minus_90 = max_training_date-timedelta(days=90)\n",
    "max_training_date_minus_180 = max_training_date-timedelta(days=180)\n",
    "hist_ratings_30 = df.query('date<=@max_training_date_minus_30').sort_values(\"date\",ascending=False).drop_duplicates(['user_id','time_control'])\n",
    "hist_ratings_90 = df.query('date<=@max_training_date_minus_90').sort_values(\"date\",ascending=False).drop_duplicates(['user_id','time_control'])\n",
    "hist_ratings_180 = df.query('date<=@max_training_date_minus_180').sort_values(\"date\",ascending=False).drop_duplicates(['user_id','time_control'])\n",
    "hist_ratings_180.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peak ratings\n",
    "hist_ratings_peak = df_training.sort_values(\"rating\",ascending=False).drop_duplicates(['user_id','time_control'])\n",
    "outcome_ratings_peak = df_outcomes.sort_values(\"rating\",ascending=False).drop_duplicates(['user_id','time_control'])\n",
    "hist_ratings_peak.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add features to base table\n",
    "df_base = latest_training_ratings.merge(hist_ratings_30[['user_id','time_control','rating']],\n",
    "                how='left',on=['user_id','time_control'],suffixes=['_latest','_30']).merge(\n",
    "            hist_ratings_90[['user_id','time_control','rating']],\n",
    "                how='left',on=['user_id','time_control']).merge(\n",
    "            hist_ratings_180[['user_id','time_control','rating']],\n",
    "                how='left',on=['user_id','time_control'],suffixes=['_90','_180']).merge(\n",
    "            hist_ratings_peak[['user_id','time_control','rating']].rename(columns={'rating':'rating_peak'}),\n",
    "                how='left',on=['user_id','time_control'])\n",
    "df_base['rating_30_diff'] = df_base['rating_latest']-df_base['rating_30']\n",
    "df_base['rating_90_diff'] = (df_base['rating_latest']-df_base['rating_90']).combine_first(df_base['rating_30_diff'])\n",
    "df_base['rating_180_diff'] = (df_base['rating_latest']-df_base['rating_180']).combine_first(df_base['rating_90_diff'])\n",
    "df_base['rating_peak_diff'] = df_base['rating_latest']-df_base['rating_peak']\n",
    "df_base['time_control_copy'] = df_base['time_control']\n",
    "df_base['rating_latest_rounded'] = df_base['rating_latest'].round(-2)\n",
    "df_base['rating_latest_squared'] = df_base['rating_latest']**2\n",
    "df_base = pd.get_dummies(df_base,columns=['time_control_copy'],prefix_sep=\"\")\n",
    "df_base.columns = [x.replace(\"time_control_copy\",\"\").lower() for x in df_base.columns]\n",
    "print(df_base.shape)\n",
    "df_base.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to people who have played rated games in the time control before 30 days ago...\n",
    "# ... and have played at least one rated game in the time control within the last 30 days\n",
    "df_base = df_base[(df_base['rating_30'].notna())&(df_base['date']>=max_training_date_minus_30)]\n",
    "df_base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the distribution of rating gains over the two year period?\n",
    "## Use this to come up with reasonable target rating ranges where I'll have a decent sample size to work with when estimating how long it'll take\n",
    "df_max_rating_gains = df_base.merge(outcome_ratings_peak,on=['user_id','time_control'],how='inner')\n",
    "df_max_rating_gains['max_gain'] = df_max_rating_gains['rating']-df_max_rating_gains['rating_latest']\n",
    "df_max_rating_gains['rating_bucket'] = df_max_rating_gains['rating_latest'].apply(lambda x: 1 if x < 1550 else (2 if x < 1900 else 3))\n",
    "df_max_rating_gains.groupby(\"rating_bucket\")['max_gain'].describe(percentiles=[.25,.5,.75,.9,.95,.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate target ratings\n",
    "df_targets = pd.concat([df_base for x in range(5)])\n",
    "def get_target_rating_gain(x):\n",
    "    die = np.random.randint(1,4)\n",
    "    if die == 1:\n",
    "        return np.random.randint(1,100)\n",
    "    elif die == 2:\n",
    "        return np.random.randint(1,300)\n",
    "    elif die == 3:\n",
    "        if x < 1550:\n",
    "            return np.random.randint(1,650)\n",
    "        elif x < 1900:\n",
    "            return np.random.randint(1,450)\n",
    "        else:\n",
    "            return np.random.randint(1,350)\n",
    "    else:\n",
    "        print(1/0)\n",
    "\n",
    "df_targets['target_rating_gain'] = df_targets['rating_latest'].apply(get_target_rating_gain)\n",
    "df_targets['target_rating'] = df_targets['rating_latest'] + df_targets['target_rating_gain']\n",
    "df_targets['target_rating_gain_rounded'] = df_targets['target_rating_gain'].round(-2)\n",
    "df_targets['target_rating_gain_squared'] = df_targets['target_rating_gain']**2\n",
    "print(df_targets.shape)\n",
    "df_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets.groupby(\"rating_latest_rounded\")['target_rating_gain'].describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(df_targets.sample(1000),aes(x='rating_latest',y='target_rating')) +\n",
    " geom_point() +\n",
    " scale_x_continuous(breaks=list(range(800,2500,200))) +\n",
    "  scale_y_continuous(breaks=list(range(800,2500,200)))\n",
    "\n",
    "        \n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_targets.copy()\n",
    "df_temp = df_temp.merge(df_outcomes,on=['user_id','time_control'],how='outer',suffixes=['_latest','_future'])\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Successes - filter to where future rating >= target rating, then take earliest date for each user/time control\n",
    "df_successes = df_temp.query('rating>=target_rating').sort_values(\"date_future\").drop_duplicates(['user_id','time_control','target_rating'])\n",
    "print(df_successes.shape)\n",
    "df_successes.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Successes and failures \n",
    "df_bin = df_targets.merge(df_successes[['user_id','time_control','target_rating','date_future']],on=['user_id','time_control','target_rating'],how='left')\n",
    "# Was the target rating achieved?\n",
    "df_bin['y_bin'] = df_bin['date_future'].notna().astype(int)\n",
    "# If so, when?\n",
    "df_bin['y_cont'] = (df_bin['date_future']-max_training_date).dt.days\n",
    "print(df_bin.shape)\n",
    "df_bin.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont = df_bin[df_bin['y_bin']==1].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bin_by_rating = df_bin.groupby([\"rating_latest_rounded\",\"time_control\"])['y_bin'].agg([np.mean,len])\n",
    "(ggplot(y_bin_by_rating[y_bin_by_rating['len']>=25].reset_index(),\n",
    "        aes(x='rating_latest_rounded',y='mean',color='time_control')) +\n",
    " geom_point() +\n",
    "      scale_x_continuous(breaks=list(range(600,2600,200))) +\n",
    "         ylim([0,1])\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bin_by_gain = df_bin.groupby([\"target_rating_gain_rounded\",\"time_control\"])['y_bin'].agg([np.mean,len])\n",
    "(ggplot(y_bin_by_gain[y_bin_by_gain['len']>=25].reset_index(),\n",
    "        aes(x='target_rating_gain_rounded',y='mean',color='time_control')) +\n",
    " geom_point() +\n",
    "         ylim([0,1])\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_by_quant_vars = df_bin.groupby(['target_rating_gain_rounded','rating_latest_rounded'])['y_bin'].mean().reset_index().round(2)\n",
    "bin_by_quant_vars.pivot(index='target_rating_gain_rounded',columns='rating_latest_rounded',values='y_bin').iloc[:-2,6:-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(bin_by_quant_vars.query(\"rating_latest_rounded>=1200\"),aes(x='target_rating_gain_rounded',y='y_bin',group='rating_latest_rounded',\n",
    "       color='rating_latest_rounded')) +\n",
    "geom_line())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As target rating gain increases, the effect of latest rating should go from zero to more negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_days_by_quant_vars = df_cont.groupby(['target_rating_gain_rounded','rating_latest_rounded'])['y_cont'].mean().reset_index().round()\n",
    "mean_days_by_quant_vars.pivot(index='target_rating_gain_rounded',columns='rating_latest_rounded',values='y_cont').iloc[:-1,6:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_days_by_quant_vars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cont_by_rating = df_cont.groupby([\"rating_latest_rounded\",'time_control'])['y_cont'].agg([np.mean,len]).reset_index()\n",
    "y_cont_by_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(y_cont_by_rating.query('len>=25'),aes(x='rating_latest_rounded',y='mean',color='time_control')) +\n",
    "        geom_point() +\n",
    "    ylim(0,500) +\n",
    "     scale_x_continuous(breaks=list(range(600,2600,200)))\n",
    "        \n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_outcome_by_group = df_cont.groupby(['target_rating_gain_rounded','time_control','rating_latest_rounded'])['y_cont'].agg([np.mean,len]).reset_index()\n",
    "(ggplot(mean_outcome_by_group.query('len>=30'),aes(x='target_rating_gain_rounded',y='mean')) +\n",
    "      geom_point())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier checks\n",
    "## High gains\n",
    "df_cont['target_rating_gain'].describe(percentiles=[x/10 for x in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Quick gains\n",
    "df_cont[df_cont['target_rating_gain']>100]['y_cont'].describe(percentiles=[x/10 for x in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_predictors = ['target_rating_gain','rating_latest','blitz','bullet','rapid','rating_peak_diff','rating_180_diff']\n",
    "df_bin_predictors = sm.add_constant(df_bin[class_predictors])\n",
    "#logit = sm.Logit(endog=df_bin['y_bin'],exog=df_bin_predictors).fit()\n",
    "logit = smf.logit(formula=\"\"\"\n",
    "y_bin~target_rating_gain*rating_latest*bullet+target_rating_gain*rating_latest*blitz+\n",
    "target_rating_gain*rating_latest*classical+\n",
    "\n",
    "rating_peak_diff*target_rating_gain+rating_180_diff*bullet+rating_180_diff*blitz+\n",
    "\n",
    "target_rating_gain_squared*rating_latest*bullet\n",
    "\"\"\",data=df_bin).fit()\n",
    "logit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "regress_predictors = ['target_rating_gain','rating_latest','blitz','bullet','rapid','rating_peak_diff','rating_90_diff']\n",
    "df_cont_predictors = sm.add_constant(df_cont[regress_predictors])\n",
    "#ols = sm.OLS(endog=df_cont['y_cont'],exog=df_cont_predictors).fit()\n",
    "ols = smf.ols(formula=\"\"\"\n",
    "y_cont~target_rating_gain_squared+\n",
    "rating_latest_squared+\n",
    "target_rating_gain*rating_latest*bullet+target_rating_gain*rating_latest*blitz+target_rating_gain*rating_latest*classical+\n",
    "rating_peak_diff*bullet+rating_peak_diff*blitz+rating_peak_diff*classical+\n",
    "rating_90_diff*blitz+rating_90_diff*classical\n",
    "\n",
    "\"\"\",data=df_cont).fit()\n",
    "ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin['prob'] = logit.predict(df_bin)\n",
    "df_bin['prob'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(df_bin['prob'].mean(),3))\n",
    "print(round(df_bin['y_bin'].mean(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(((df_bin['prob']-df_bin['y_bin'])**2).mean(),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in df_bin['time_control'].unique():\n",
    "    data = df_bin.query(\"time_control==@x\")\n",
    "    print(x)\n",
    "    print(round(((data['prob']-data['y_bin'])**2).mean(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin['decile'] = pd.qcut(df_bin['prob'],q=10)\n",
    "deciles = df_bin.groupby('decile')[['prob','y_bin']].mean().reset_index()\n",
    "deciles['index'] = np.arange(len(deciles))\n",
    "decile_probs = deciles[['prob','index']].rename(columns={\"prob\":\"value\"})\n",
    "decile_probs['variable'] = 'prob'\n",
    "decile_actuals = deciles[['y_bin','index']].rename(columns={\"y_bin\":\"value\"})\n",
    "decile_actuals['variable'] = 'actual'\n",
    "deciles = pd.concat([decile_probs,decile_actuals],axis=0)\n",
    "(ggplot(deciles,aes(x='index',y='value',fill='variable')) +\n",
    " geom_bar(stat='identity',position='dodge')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(df_bin.query('y_bin==0'),aes(x='prob')) +\n",
    "geom_histogram(bins=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the ones with high-prob that are zeros (where we're overpredicting)\n",
    "df_bin.query(\"prob>=.75&y_bin==0\").groupby([\"time_control\",\"rating_latest_rounded_300\",\"target_rating_gain_rounded\"]).size().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(df_bin.query('y_bin==1'),aes(x='prob')) +\n",
    "geom_histogram(bins=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(df_bin,aes(x='prob')) +\n",
    "geom_histogram(bins=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin['rating_latest_rounded_200'] = 200*np.ceil(df_bin['rating_latest_rounded']/200).astype(int)\n",
    "df_bin['rating_latest_rounded_300'] = 300*np.ceil(df_bin['rating_latest_rounded']/300).astype(int)\n",
    "xtabs_bin = df_bin.groupby(['time_control','target_rating_gain_rounded','rating_latest_rounded_200'])[['y_bin','prob']].agg([np.mean,len]).iloc[:,:-1].round(2)\n",
    "xtabs_bin.columns = ['prop_actual','n','mean_prob']\n",
    "xtabs_bin.reset_index(inplace=True)\n",
    "xtabs_bin['diff'] = xtabs_bin['mean_prob'] - xtabs_bin['prop_actual']\n",
    "xtabs_bin['abs_diff'] = xtabs_bin['diff'].abs()\n",
    "xtabs_bin.query(\"n>=50\").sort_values(\"abs_diff\",ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin.groupby(['rating_latest_rounded_200'])[['y_bin','prob']].agg([np.mean,len]).iloc[:,:-1].round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin.groupby(['target_rating_gain_rounded'])[['y_bin','prob']].agg([np.mean,len]).iloc[:,:-1].round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtabs_bin.query(\"time_control=='Blitz'\").pivot(index='target_rating_gain_rounded',columns='rating_latest_rounded_200',values='prop_actual').iloc[:-1,2:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtabs_bin.query(\"time_control=='Blitz'\").pivot(index='target_rating_gain_rounded',columns='rating_latest_rounded_200',values='mean_prob').iloc[:-1,2:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtabs_bin.query(\"time_control=='Blitz'\").pivot(index='target_rating_gain_rounded',columns='rating_latest_rounded_200',values='diff').iloc[:-1,2:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont['pred'] = ols.predict(df_cont)\n",
    "#df_cont.loc[df_cont['pred']<0,'pred'] = 0\n",
    "df_cont['pred'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_cont[df_cont['pred']<0])/len(df_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont['error'] = df_cont['pred']-df_cont['y_cont']\n",
    "df_cont['abs_error'] = df_cont['error'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont['error'].describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont['abs_error'].describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_summary = df_cont.groupby(['target_rating_gain_rounded','rating_latest_rounded','time_control'])[['pred','y_cont','abs_error','error']].agg([np.mean]).round().astype(int)\n",
    "sizes = df_cont.groupby(['target_rating_gain_rounded','rating_latest_rounded','time_control']).size().reset_index()\n",
    "sizes.rename(columns={0:\"n\"},inplace=True)\n",
    "error_summary.columns = ['mean_pred','mean_actual','mean_abs_error','mean_error']\n",
    "error_summary = error_summary.reset_index().merge(sizes,on=['target_rating_gain_rounded','rating_latest_rounded','time_control'])\n",
    "error_summary = error_summary.query('n>30')\n",
    "error_summary.sort_values(\"mean_error\",ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont.groupby(\"time_control\")['abs_error'].mean().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_summary.query(\"time_control=='Bullet'\").pivot(index='target_rating_gain_rounded',columns='rating_latest_rounded',values='mean_actual').iloc[:-1,2:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_summary.query(\"time_control=='Bullet'\").pivot(index='target_rating_gain_rounded',columns='rating_latest_rounded',values='mean_pred').iloc[:-1,2:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_summary.query(\"time_control=='Bullet'\").pivot(index='target_rating_gain_rounded',columns='rating_latest_rounded',values='mean_error').iloc[:-1,2:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_summary.query(\"time_control=='Bullet'\").pivot(index='target_rating_gain_rounded',columns='rating_latest_rounded',values='n').iloc[:-1,2:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(error_summary.query(\"time_control=='Blitz'&target_rating_gain_rounded<=300\")) +\n",
    "geom_point(aes(x='rating_latest_rounded',y='mean_pred'),color='red')+\n",
    " geom_point(aes(x='rating_latest_rounded',y='mean_actual'),color='blue')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_rating_history(response_json):\n",
    "    rating_history = dict()\n",
    "    for x in response_json:\n",
    "            if x['name'] in ['Bullet','Blitz','Rapid','Classical']:\n",
    "                tbl = pd.DataFrame(x['points'])\n",
    "                tbl.columns = ['year','month','day','rating']\n",
    "                tbl['month'] = tbl['month']+1\n",
    "                tbl['date'] = pd.to_datetime(tbl.year*10000+tbl.month*100+tbl.day,format='%Y%m%d')\n",
    "                rating_history[x['name']] = tbl\n",
    "    return(rating_history)\n",
    "\n",
    "def get_prob_success(predictor_values):\n",
    "    return 1\n",
    "\n",
    "def get_predicted_days(predictor_values):\n",
    "    predicted_days = 0\n",
    "    for i in range(len(ols.params)):\n",
    "        var_name = ols.params.index[i]\n",
    "        coef = ols.params.values[i]\n",
    "        if ':' in var_name:\n",
    "            var_names = var_name.split(\":\")\n",
    "            value = 1\n",
    "            for j in var_names:\n",
    "                value *= predictor_values[j]\n",
    "        else:\n",
    "            value = predictor_values[var_name]\n",
    "        predicted_days += coef*value\n",
    "    return(round(predicted_days))\n",
    "\n",
    "def score(username,target_rating_gain,target_time_control):\n",
    "    url = f'https://lichess.org/api/user/{username}/rating-history'\n",
    "    response = requests.get(url)\n",
    "    response_json = response.json()\n",
    "    if response.status_code != 200:\n",
    "        return(f\"API ERROR: {response.status_code}\")\n",
    "    else:\n",
    "        rating_history = process_rating_history(response_json)\n",
    "        target_rating_history = rating_history[target_time_control]\n",
    "        target_rating_history['today'] = datetime.today()\n",
    "        rating_latest = target_rating_history['rating'].values[-1]\n",
    "        predictor_values = dict(Intercept=1,target_rating_gain=target_rating_gain,\n",
    "        target_rating_gain_squared=target_rating_gain**2,\n",
    "        rating_latest=rating_latest,\n",
    "        rating_latest_squared = rating_latest**2,\n",
    "        bullet = int(target_time_control == 'bullet'), blitz = int(target_time_control == 'blitz'),\n",
    "        rapid = int(target_time_control == 'rapid'), classical = int(target_time_control == 'classical'),\n",
    "        rating_peak_diff = rating_latest-target_rating_history['rating'].max(),\n",
    "        # TO DO\n",
    "        rating_90_diff = 200#rating_latest-target_rating_history[target_rating_history['date']<=target_rating_history['today']].values[-1]\n",
    "\n",
    "                           )\n",
    "        prob_success = get_prob_success(predictor_values)\n",
    "        predicted_days = get_predicted_days(predictor_values)\n",
    "        return(prob_success,predicted_days)\n",
    "score(username = \"\",target_rating_gain = 50,\n",
    "      target_time_control = \"Bullet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datetime.date(datetime.today()-timedelta(days=90)).strftime(format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_rating_history.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "- Target time control (likely interacted with various other features)\n",
    "- Target rating gain\n",
    "- Current rating (likely nonlinear relationship)\n",
    "- Rating growth in last 30 days / 90 days / 180 days\n",
    "- Rating volatility measures\n",
    "- Peak historical rating relative to current rating\n",
    "- Rating in other time controls + puzzles\n",
    "- Rating growth in other time controls + puzzles\n",
    "- Difference between other time control ratings + target time control rating\n",
    "- How long you've been on lichess\n",
    "- How many games you've played (ever, and within last 30 days, and within the target time control - if you haven't played many it could mean more uncertainty). Consider that most discord bot users will have played more recent rated games in the target time control than the typical user in the training data. \n",
    "- Last time you played a rated game in the target time control (if it's a long time ago, it could mean more uncertainty)\n",
    "\n",
    "## Outcomes\n",
    "- Will you ever achieve a rating that's X rating points higher than your current rating in the next Y months (X is calculated from target rating submitted by user, Y = 24?)\n",
    "- If so, when will you first reach the target rating? (point estimate + prediction interval of dates) - use number of days as outcome, then transform to date for the bot message\n",
    "- Try to tweak model to avoid negative predictions, and manually override when needed. Same with predictions greater than 2 years out.\n",
    "\n",
    "\n",
    "## Notes:\n",
    "- Use cross-validation since sample size might be constrained\n",
    "- Need to impute nulls\n",
    "- Need to write code for scoring based on discord input (including lichess API querying)\n",
    "- Need to figure out how to make prediction interval\n",
    "- Add more comments + documentation to final version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
